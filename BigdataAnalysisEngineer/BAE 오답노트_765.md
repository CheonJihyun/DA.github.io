# PART 7 기출복원문제 - 2회독

## 제7회

1\. 하둡 분산 파일 시스템(HDFS)에서 네임 노드 오류 발생 시 데이터 읽기 쓰기가 불가능

2\. CRISP-DM 방법론 6단계

- 업무(사업, 비즈니스) 이해
- 데이터 이해
- 데이터 준비
- 모델링
- 평가
- 전개

5\. 빅데이터 분석 방법론

- 분석 기획 단계: 비즈니스 이해 및 범위 설정, 프로젝트 정의 및 계획 수립, 츠로젝트 위험 계획 수립

7\.

- 분석 마스터플랜 수립: 전략적 중요도, 비즈니스 성과, 실행 용이성 고려
- 분석 로드맵 수립: 업무 내재화 적용 수준, 분석 데이터 적용 수준, 기술 적용 수준 고려

8\. 기업의 분석 수준을 진단하는 항목

- 분석 능력: 분석 업무, 분석 데이터, 분석 기법 등
- 분석 준비도: 분석 조직, 분석 인프라, 분석 문화 등 (규모는 안 봄)

11\. 하드스킬: 빅데이터 지식, 분석 기술, 통계 이론

14\. 무결성: 데이터가 처리되는 과정에서 변경되거나 손상되지 않고 유지함을 보장하는 특성

18\. 빅데이터 플랫폼 > 플랫폼 계층: 데이터의 수집, 저장, 처리, 분석이 수행되는 계층

19\. MongoDB

- 오토샤딩 (같은 테이블 스키마를 가진 데이터를 다수의 데이터베이스에 자동으로 분산하여 저장)
- 처리속도가 빠르며 문서 지향 NoSQL

24\. 데이터 컬럼 이름 변경은 파생변수 생성이 아님

28\. SMOTE 기법: 불균형 데이터 처리 방법

42\. Attention: 문맥에 따라 집중할 단어를 결정하는 방식 (Transformer와 관련된 용어)

- Generator - GAN
- Forget gate - LSTM
- Feature map - CNN

44\. 가설 검정

- 단측 검정: 음의 방향과 양의 방향 중 한 방향만을 살펴보는 검정
- 양측 검정: 기각역을 양쪽으로 설정하는 검정

46\. 앙상블

- Boosting: Gradient Boost
- Bagging: Extra Trees, Random Forest

47\. 종류 예측 -> 분류

49\. 분할적 군집화: DBSCAN, K-평균 군집 분석, SOM

50\. Bootstrap을 사용하는 기법은 Bagging

55\. 향상도(lift) = P(B|A) / P(B) = (A와 B를 포함하는 거래 수) / (A를 포함하는 거래 수) X (B를 포함하는 거래 수)

56\. 모델의 복잡도가 높아져 SSE가 작아지면 과적합 가능성이 클 수 있으나 항상 과적합 모델인 것은 아님

59\. 잔차의 자유도 = 포본크기 - 2

63\. 엘보우 기법: K-평균 군집 분석에서 최적 K 평균을 구하는 방법

66\.

비교 시각화

- 히트맵, 체르노프 페이스, 스타 차트, 평행 좌표계, 다차원 척도법 등
- 다양한 변수를 한 번에 비교할 수 있음

관계 시각화

- 상관관계 분석을 할 수 있음
- 산포도와 버블 차트로 표현 가능
- 두 개 이상의 변수 간 관계를 나타냄

67\. 의사결정나무 정지규칙

- depth가 최대일 때
- 마지막 가지 끝에 남은 개수가 일정 개수 이하일 때
- 분기를 더 하더라도 불순도 지표가 개선되지 않을 때

68\. 앙상블 기법

- k = 1, 5, 7인 KNN 모델을 결합시키는 것이 예시가 될 수 있음
- 앙상블 기법 중 voting을 통해 서로 다른 알고리즘으로 생성한 분류 모델의 결과를 합칠 수 있음
- 데이터 샘플링 시 중복을 허용하는 방법이 Bagging, 중복을 허용하지 않는 방법이 Pasting

71\. Naive Bayes: 베이즈 정리를 적용한 분류기, 부스팅 알고리즘에 해당하지 않음

73\. 정준상관 분석: 몇 개의 변수로 이루어진 집단 사이의 연관성(선형 상관관계)을 구하는 방법

- PCA: 데이터들의 주성분을 찾음
- 요인분석: 변수들 간 상관관계를 이용하여 유사한 변수끼리 묶어줌
- 데이터 내에서 연관규칙을 발견

76\. 회귀 모델 평가 지표: MSE, RMSE, MAPE 등

77\. F1-score = 2 x (precision x recall) / (precision + recall)

78\. 레이더 차트: 여러 데이터 한 눈에 비교

## 제6회

3\.

## 제5회

2\. CRISP-DM 방법론 6단계

- 업무(사업, 비즈니스) 이해
- 데이터 이해
- 데이터 준비
- 모델링
- 평가
- 전개

3\. 인공지능 > 머신러닝 > 딥러닝

7\. 개인정보보호법 데이터 3법

- 개인정보 보호법, 정보통신망법, 신용정보법의 개정안
- 개정을 통해 가명정보 개념 도입 -> 가명정보 주체의 동의 없이 데이터 활용이 가능해짐

20\. 텍스트 마이닝: 비정형 텍스트 데이터에서 패턴 또는 관계를 추출하여 유의미한 정보를 찾아내는 기법

21\. 포아송 분포: 이산형 확률 분포 중 주어진 시간 또는 영역에서 어떤 사건의 발생 횟수를 나타내는 확률 분포

22\. 95% 신뢰구간 -> 1.96

23\.

- 체중이 변화하였는가? -> 양측검정
- 체중이 줄어들었는가? -> 단측검정

24\.

- 두 확률변수 X, Y가 독립 -> 공분산 Cov(X,Y) = 0
- 공분산 Cov(X,Y) = 0이라고 반드시 두 변수가 독립은 아님

26\. 클래스 불균형 데이터 처리: 임곗값 조정, 언더샘플링, 오버샘플링 등으로 해결 가능

28\. T 분포

- 모표준편차를 모를때
- 표본의 크기가 30보다 작을때
- 집단 간 평균이 동일한지 알고 싶을때
- 이때 자유도는 N-1

29\. 피어슨 상관계수가 1에 너무 가까운 변수들이 존재할 경우 -> 모델 성능이 떨어지거나 불안정해질 수 있음

31\. 중심 극한 정리: 표본의 개수가 커지면 모집단의 분포와 상관없이 표본 분포가 정규 분포에 근사한다

- 표본의 크기가 작으면 표본 평균과 모평균의 기댓값이 다를 수 있다

32\. 타깃 인코딩: 각 범주의 레이블 값이 학습 데이터에 존재하는 종속변수의 평균값을 정해짐

40\. 초기하분포는 이산확률분포

43\. 과적합 방지 기법

- 드롭아웃
- 데이터 증강: 기존의 데이터를 조금씩 변형, 추가하여 데이터 수 늘림

45\. 가지치기: 의사결정나무 모형에서 과적합을 방지하는 방법 (인공신경망에서 쓰이지 X)

46\. h=4에서 가지가 2개

47\. Pos-Tagging: 형태소에 품사를 붙이는 것

50\. Odds = (사건이 발생할 확률) / (사건이 발생하지 않을 확률) -> 0 ~ 무한대의 범위

51\. ARIMA 모형

- 정상성을 보이는 시계열은 추세나 계절성이 없음
- AR 모델은 변수의 과거 갑 ㅅ을 이용
- MA 모델은 과거 예측 오차를 이용
- 백색잡음과정은 대표적인 정상 시계열 -> 독립적이고 동일한 분포를 따름

53\. 만-휘트니 검정과 윌콕슨 순위합 검정 모두 두 집단의 중위수 차이 검정에 사용 가능한 비모수 검정 방법

55\. 신뢰도: A 상품을 샀을 때 B 상품을 살 조건부 확률에 대한 척도

56\. 요인 분석

- 고차원의 데이터를 저차원으로 축소
- 변수들의 상관관계를 기반으로 공통의 요인을 찾음
- 요인 회전 방법: VariMax, QuartMax, EquaMax, Oblimin, ProMax
- 요인 분석 결과로 만들어진 새로운 변수들은 서로 대등

57\. 공분산 분석(ANCOVA)는 독립변수 이외의 잡음인자를 통계적으로 제어(공변량)하고 범주형 독립변수와 연속형 종속변수의 상관관계를 분석하는 방법

58\. 회귀모형

- 다중 회귀모형에서 통계적 유의성을 확인하는 방법은 F-통계량
- 독립변수가 2개 이상이고 회귀계수가 2차 이상이면 다항회귀 모형
- 회귀모형의 변수 선택법: 전진 선택법, 후진 제거법, 단계 선택법

60\. 데이터 분석 결과 산출물: 분석 계획서, 변수 정의서, EDA 보고서, 분석 결과 보고서, 분석 모델 등

61\. ROC Curve 축을 구성하는 지표

- x축: 거짓 긍정률(FPR) = 1 - 특이도
- y축: 참 긍정률(TPR) = 민감도

64\. 표본의 충분석은 모델 개발할 때는 중요한 고려 요소지만, 최종 모델 평가에는 고려되지 않음

65\. ROC Curve로는 혼동행렬을 구할 수 없음

66\. MSE = Mean Squared Error (제곱이 붙어야)

68\. 일반화 선형 모델(GLM)

- 종속변수의 분포를 정규분포를 포함한 다양한 분포로 확장 -> 종속변수의 정규성이 성립하지 않아도 사용 가능
- 연결함수를 사용하여 선형예측자와 종속변수의 평균을 연결
- 종속변수가 이항분포인 경우 logit 함수, 포아송분포인 경우 log 함수가 연결함수
- 로지스틱 회귀가 대표적인 일반화 선형 모형

69\. 비교시각화: 히트맵, 체르노프 페이스, 스타차트

70\. 관계시각화: 산점도, 버블차트, 산점도행렬

- 분포시각화: 누적막대그래프

71\. F1-score = 2 * (민감도 * 정밀도) / (민감도 + 정밀도)

74\. 평가 데이터셋 다양화 -> 일반화 성능을 더 잘 확인할 수 있음, 모델 최적화와는 무관

75\. 재현율 = TP / (TP + FN)

76\. 지지도, 향상도 -> 연관성 분석의 성능을 평가

## 제4회

7\. 비식별 정보는 불특정 다수에게 공개할 수 없다.

11\. 스파크(Spark)

- 하둡의 맵리듀스와 동일한 역할 + 빠른 성능을 위해 인메모리 캐싱 기능 제공
- 배치 처리, 스트리밍 분석, 머신러닝, 그래프 데이터베이스 등을 지원
- 함수형 프로그래밍 언어인 스칼라 사용
- 데이터 추출, 적재 시간을 줄여 실시간 분석에 용이

14\. 데이터 품질 지표: 정확성, 완정성, 적시성, 일관성

- 불편성(Unbiasedness): 모든 가능한 표본에서 얻은 추정량의 기댓값이 모집단의 모수와 차이가 없음 (점추정의 조건)

18\. 데이터레이크: 대량의 데이터를 원시 형태로 저장, 필요한 시점에 추출하여 가공/분석

19\. 개인정보 차등보호(Differential Privacy): 데이터에 수학적인 노이즈를 추가하는 기술 (데이터 마스킹 기법 중 하나)

개인정보 비식별화 기술
- 가명 처리
- 총계 처리
- 데이터 삭제
- 데이터 범주화
- 데이터 마스킹

22\.

유의수준
- 제1종 오류(귀무가설이 사실인데 허위라고 결론 내리는 것)를 범할 확률의 최댓값

유의확률
- 귀무가설이 맞다는 전제하에 표본에서 실제로 관측된 통계치와 같거나 더 극단적인 통계치가 관측될 확률

23\. 패널 데이터: 같은 응답자가 여러 해에 걸쳐서 반복적으로 응답한 것을 기록한 것 (<span style="color:orange">공간 데이터가 아니라서 시공간 데이터가 아닌건가?</span>)

24\. 이상값을 찾는 방법: 박스플롯, 산점도, 표준정규분포, 기하평균, 히스토그램, 업무 지식

25\. 두 변수 x, y의 상관계수가 0일 때 = 두 변수 x, y는 선형적인 관계가 없다

28\. 주성분 분석: 기존 변수들을 선형 결합하여 새로운 변수가 만들어짐 -> 주성분의 의미를 직관적으로 해석하기 어려움

32\. Apriori = 연관규칙분석(Association Rule) / 장바구니 분석

- 컨텐츠 기반 추천에 활용
- 관련 지표: 지지도, 신뢰도, 향상도

34\. 임곗값 이동: 임곗값(Threshold)을 데이터가 많은 쪽으로 이동시키는 방법, 학습 단계에서는 변화 없이 학습하고 테스트 단계에서 임곗값을 이동하는 방법

<span style="color:orange">보기가 이상...</span>

35\. 공분산 연산

- $V(X+Y) = V(X) + V(Y) + 2Cov(X,Y)$
- X, Y가 독립이면 $Cov(X,Y) = 0$

39\. 초기하 분포: 비복원 추출 <-> 이항 분포: 복원 추출

47\. 오토인코더(Auto Encoder)

- 인공 신경망을 활용한 비지도 학습 기법
- 입력 특성 간 상관관계를 학습하여 출력을 재구성
- 인코드 입력수와 디코드 출력수는 동일 (출력은 입력에 대한 예측)
- 입력층의 뉴런 수보다 은닉층의 뉴런 수가 항상 적은 것은 아님
  
51\. 민감도(Sensitivity, Recall, 재현율) = 실제 긍정인 것 중 긍정으로 올바르게 예측한 것

52\. 정확도 -> 불균형 데이터 평가에 사용되지 않음

54\. 발전 방향: 인공신경망 -> 딥러닝

55\. 비계층적 군집방식: K 평균 군집 분석, SOM(자기조직화지도), 혼합분포군집

계층적 군집분석
- 군집 수를 사전에 설정하지 않아도 됨
- 덴드로그램으로 표현 가능
- N개의 군집으로 시작하여 군집 간 거리를 기준으로 가장 가까운 군집끼리 병합

60\. Softmax 함수

- 다중분류 출력층에 사용
- 입력받은 값을 출력으로 0~1 사이의 값으로 모두 정규화
- 출력값들의 총합이 항상 1이 됨

61\. 시각화 기법

- 시간 시각화: 막대그래프, 산점도, 선그래프, 계단식그래프, 영역차트
- 공간 시각화: 등치지역도, 도트플롯맵, 버블플롯맵, 등치선도, 카토그램
- 관계 시각화: 산점도, 산점도행렬, 버블차트, 히스토그램
- 비교 시각화: 히트맵, 스타차트, 체르노프페이스, 평행좌표그래프

62\.

- 하이퍼파라미터 최적화 기법: 베이지안 최적화, 그리드 탐색, 랜덤 탐색
- 파라미터 최적화 기법: 경사하강법, 모멘텀, AdaGrad, RMSProp, Adam

64\. 거짓긍정률 = 1 - 특이도

68\. 정밀도 = TP / (TP + FP)

71\. 매개변수 최적화와 하이퍼파라미터 튜닝은 무관

72\. 전체 데이터에 대한 업데이트 -> 배치 경사하강법

<img src='img/param.png'>

75\. 훈련용 데이터셋은 50~60% 비율이 적당

76\.

- 히스토그램은 도수 분포, 막대 그래프는 범주별 데이터값
- 히스토그램은 관계 시각화 기법

<span style='color:oragne'>히스토그램과 막대 그래프는 다르다</span>

78\. 분석 목적을 명확히 하는 것에 주안점을 두는 활동은 과제 정의서 작성 또는 과제 기획

80\. 분석모형 리모델링은 주기적으로 수행해야 하는 업무는 아님 (성능이 크게 떨어졌을 때만)

## 제3회

1\. 빅데이터 분석 방법론 중 분석 기획

- 프로젝트 방향성 설정
- 과제 현황 파악
- 성공적인 분석 결과를 도출하기 위한 중요한 사전 작업

6\. 데이터 분석 과정

- 텍스트 데이터 확인, 수집 및 데이터 분석
- 탐색적 데이터 분석 및 데이터 시각화
- 모델 평가 및 모델 검증

데이터 준비 단계

- 데이터 수집, 저장 및 정합성 검증


7\. 빅데이터 기반 인공지능 -> 인간의 통찰력에 대한 개입 없이 필요한 특징을 자동으로 설정할 수 있어야

8\. 비식별화 조치가 취해진 데이터는 수집, 저장, 조합, 분석 및 제3자 제공 등이 가능

9\. 데이터 엔지니어의 역량 -> 데이터 가공 자동화, 시스템 개발 능력

11\. GDPR(General Data Protection Regulation): EU 회원국에 일괄적으로 적용되는 개인정보 보호법

15\. 분석 과제 정의 단계

- 필요한 데이터, 데이터 수집과 분석 난이도, 분석 방법과 수행 주기, 상세 분석 과정, 분석 결과에 대한 검증 책임자 등을 포함

16\. 데이터 웨어하우스의 특성

- 비소멸성(비휘발성)
- 통합성
- 주제 정확성(주제 지향성)
- 시계열성(시간에 따라 변화)

18\. NoSQL: 전통적인 관계형 데이터베이스보다 유연한 데이터의 저장 및 검색을 위한 메커니즘 제공

24\. 요인분석

- 영향력이 큰 주요 변수와 유사한 변수를 제거하는 것이 아님
- 다수의 변수들의 정보손실을 억제하면서 소수의 요인으로 축약하는 기법

25\. Box-Cox 변환: 데이터를 정규분포에 가깝게 만들거나 데이터의 분산을 안정화

파생변수: 기존 변수에 특정 조건 혹은 함수 등을 적용하여 새롭게 통계량을 재정의

31\. 표본조사: 전수조사가 비효율적일 때 수행

전수조사: 모수에 대해 반드시 조사를 수행해야 할 때

33\. 점 추정의 조건: 불편성, 효율성, 일치성, 충족성

36\. 추출 기법

- 군집 추출 기법: 집단 내에서 이질적, 집단 간에는 동질적
- 층화 추출 기법: 집단 내에서 동질적, 집단 간에는 이질적

39\. 모집단의 분산 / n = 표본분포의 분산

45\. 분류 기준

- 종속변수가 이산형 변수인 경우: 카이제곱 통계량, 지니 지수, 엔트로피 지수
- 종속변수가 연속형 변수인 경우: F-통계량, 분산감소량

46\. 시계열 분해 요소: 체계적 성분 (추세성분, 계절성분, 순환성분) + 불규칙 성분

55\. 사회관계망분석에서 중심성을 분석하는 지표: 연결 정도 중심성, 근접 중심성, 매개 중심성, 위세 중심성(아이겐벡터 중심성) 등

- 포괄성: 중심성이 아닌 밀도를 분석하는 지표

59\. 자기회귀: 측정값이 시차에 따라 전후 값들 사이에 상관관계를 갖는 시계열 특성

60\. 각 점마다 가는 방법을 값 * 가중치로 연산 -> 새로운 값을 더한 값까지 연산해서 가중치 다시 연산 -> 모두 더하기

62\. AdaBoost: 개별 모델에 별도의 가중치를 주는 방식

- GBM: 경사하강법을 적용한 부스팅 알고리즘

69\. 카이제곱통계량 = ((관측치 - 예측치)^2 / 예측치)의 합

77\. Root Mean Squared Error(RMSE): 연속형 변수를 예측하는 회귀모델에 대한 평가지표

80\. 특이도: 실제 음성(False)을 음성(False)로 정확히 예측했는지에 대한 평가지표

## 제2회

5\. l-다양성: 민감정보의 다양성을 높여 k-익명성의 단점인 동질성 공격, 배경지식 기반 공격을 방지하기 위한 기법

6\. 개인정보 비식별화 처리 방법

- 가명처리, 범주화: 개인을 식별할 수 있는 데이터를 다른 값으로 대체하거나 그룹의 대푯값이나 구간값으로 변환하는 방법
- 섭동: 민감한 원본 자료를 감추기 위해 원본 데이터에 교란을 주어 개인의 식별을 어렵게 하는 기법

9\. 입사 지원자에 대한 신원 조회에는 개인정보 수집 및 사용에 대한 동의가 필요

10\. 정형 데이터의 품질 검증: 메타데이터 분석, 업무 규칙 적용

12\. 모형화: 분석 문제를 단순화하여 수치나 변수 사이의 관계로 정의하는 것

15\. DBMS 수집: 주로 ETL, Open API 등을 이용

16\. 데이터 분석 성숙도 모델: 도입, 활용, 확산, 최적화

18\. 분석 문제 정의의 상향식 접근법

- 프로세스 분류 -> 프로세스 흐름 분석 -> 분석요건 식별 -> 분석요건 정의
- 무엇이 문제인지 정의할 수 없을 경우 비지도 학습 기반으로 데이터 기반의 문제를 정의하고 해결방안을 탐색하는 방법

19\. 정확성: 관찰, 측정된 값이 정의된 기준에 맞도록 저장되어 있는 품질 특성

22\. 변수 선택 기법: 래퍼 기법, 필터 기법, 임베디드 기법

- 래퍼 기법:
- 필터 기법:
- 임베디드 기법:
- (주성분 기법 -> 차원축소의 방법)

26\. X +- Z x (표준편차/(n)^(1/2))

27\. 우도: 지금 얻은 데이터가 이 분포로부터 나왔을 가능도

<span style='color:orange'>우도함수 추가 학습 필요</span>

30\. 평행 차트: 입력 필드 X만큼 Y축을 만들고 동일한 행에 있는 값을 선으로 연결하여 그리는 시각화 기법

34\. 차원의 저주: 차원이 증가하면서 개별 차원 내의 학습 데이터 수가 차원의 수보다 적어져 성능이 저하되는 현상

38\. 베르누이 분포

- 이산확률분포 중 하나
- 특정 실험의 결과로 성공 또는 실패 두 가지 중 하나를 얻는 분포

43\. 합성곱신경망

- Padding = 0 -> 결과값이 작아짐
- Stride = 1 -> 1칸씩 필터를 이동하며 특징을 추출
- 필터의 크기가 3x3 이므로 입력층의 모서리가 1씩 손실됨

<span style='color:orange'>이해안됨</span>

45\. 서포트벡터머신: 데이터가 많아질수록 최적화를 위한 테스트 과정이 많아짐 -> 비교적 속도가 느린 편

46\. 다차원 척도법(MDS)

- 다차원 척도법 설명
- (주성분 분석: 공분산 행렬을 사용하여 고유값이 1보다 큰 주성분의 개수를 이용)

47\. 라쏘 회귀분석

- 중요하지 않은 변수 가중치가 완전히 0이 되어 제거되는 L1 규제를 사용한 것

55\. 라벨링을 통해 훈련하는 지도학습 + 범주화 -> 분류

62\. NN(Neural Networks) 모형의 하이퍼파라미터: 학습률, 배치크기, hidden layer 수, hidden unit 수 등

68\. 인공신경망 모형

- 파라미터: 가중치
- 하이퍼파라미터: 학습률, 배치크기, hidden unit 수 등

72\. 귀무가설 기각 -> 범주별 기대도수의 값과 관측도수 값의 차이가 충분히 크다

75\. 카파값(Kappa value)

- 0~1 사이의 값을 가짐
- 0의 값을 가지면 관측한 범중와 예측한 범주 사이에 전혀 관련성이 없음을 의미
- 1의 값을 가지면 관측한 범주와 예측한 범주가 완벽히 일치함을 의미
- 카파값 식

79\. 회귀 결정계수: 회귀모형의 적합도를 나타내는 값